-
  Q: I feel overwhelmed with this dataset. what should I do?
  A: "Take it one column at a time. Identify your target variable. For example, you could select the home price in a table of real estate prices for homes. `y = df['price']`. Then look at the dtype (data type) for each of the columns and work with just the first numeric column you see, for example the total square footage of the home. `X = df[['sqft']]`. Then you can train a linear regression to predict home price from square footage. `lr, lr = sklearn.linear_model.LinearRegression(), lr.fit(X, y)` and you can score it for accuracy with `lr.score(X, y)`. Then add one column at a time to your variable X (features) and see how your `fit` improves by checking the `score` each time."
-
  Q: "How can I filter out proper nouns from supreme court rulings so I can build a model to predict the judge's name and use that to suggest words for lawyers to use in their arguments?"
  A: "Spacy has a built-in POS tagger: `[tok.text for tok in spacy.load('en')('Hello Earth!') if tok.pos_ != 'PROPN']` or:
  >>> import spacy
  >>> nlp = spacy.load('en_core_web_md')
  >>> doc = nlp('Hello world from Hobson Lane in Mississippi sitting on the john.')
  >>> [tok.pos_ for tok in doc]
  ['INTJ', 'NOUN', 'ADP', 'PROPN', 'PROPN', 'ADP', 'PROPN', 'VERB', 'ADP', 'DET', 'PROPN', 'PUNCT']
  >>> [(tok.text, tok.pos_) for tok in doc]
  "
-
  Q: "When I bootstrapped a shuffled dataset and calculated the confidence 95% interval the mean of my actual data is well outside the 95% confidence interval. What does this mean?"
  A: "This means that the two means are statistically different and are unlikely to have occurred by chance so you can reject your null hypothesis, just as if you'd gotten a p-value that was smaller than 5% (or 1 - .95)."
-
  Q: "What is the bias-variance trade-off? What does the U shaped parabola mean when the horizontal axis is model complexity and the vertical axis is the model prediction error? #interview #teacher #student"
  A: "The bias is the mean absolute error (MAE) or mean absolute precision (MAP) on your test set. This is what you care about the most. The variance is the mean absolute error or mean absolute precision (MAP) on your training set. The bias-variance trade-off means that as you increase model complexity, while keeping the information content or variety of your features constant, both bias and variance will be reduced until eventually your your bias will start to increase, even though your variance is continuing to get smaller. Takeaway: when your test set error starts increasing, stop adding model complexity and start simplifying your model."
-
  Q: "In the bias-variance tradeoff for your model you want to reduce model variance (the error on your training set). How can you increase model complexity without adding new features (columns) to your dataset? #interview #teacher #student"
  A: "You can add addition transformations of your existing features. One easy transformation is to add an additional polynomial term, such as `x_1**2` or `x_1**3`, as a feature without adding any new feature with new information about the world. Another common way is to add a nonlinear term to your model, like the product or quotient of two features that are already included in your model, such as `x_1 * x_2` or `x_1 / x_2`. Transcendental functions are also good nonlinear transformations to try when you have  a feature variable that is proportional to time or or location (or any situation where you target variable or input feature variable might be periodic), such as `sin(x_1)` and `cos(x_1)`."
